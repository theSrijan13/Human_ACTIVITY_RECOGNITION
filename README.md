# HUMAN_ACTIVITY_RECOGNITION

This project aims to recognize human activities using sensor data from smartphones. The project uses various machine learning algorithms to classify activities such as walking, sitting, standing, etc. based on data collected from accelerometers and gyroscopes.

## Installation

Clone the repository: git clone **https://github.com/<theSrijan13>/Sensor-Based-Human-Activity-Recognition.git**
Navigate to the project directory: cd Sensor-Based-Human-Activity-Recognition
Install the required dependencies: pip install -r requirements.txt

## Usage

Navigate to the project directory: cd Sensor-Based-Human-Activity-Recognition
Run the script: python main.py
The script will load the dataset, preprocess the data, split it into training and testing sets, train the model, and generate predictions.

## Dataset

The dataset used in this project is provided by UCI Machine Learning Repository. It contains sensor data from accelerometers and gyroscopes of smartphones worn by volunteers performing various activities. The dataset has 10,299 rows and 561 columns.

## Algorithms

This project uses the following machine learning algorithms to recognize human activities:

Decision Tree
Random Forest
K-Nearest Neighbors (KNN)
Support Vector Machine (SVM)
Multilayer Perceptron (MLP) Neural Network

## Evaluation

The performance of the machine learning algorithms is evaluated using the accuracy, precision, recall, and F1-score metrics. The algorithm with the highest accuracy and F1-score is considered the best-performing algorithm.

## Contributors

Srijan Sahu
